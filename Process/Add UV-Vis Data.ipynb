{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "from scipy import interpolate, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\edwin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\oauth2client\\_helpers.py:255: UserWarning: Cannot access OT2creds.txt: No such file or directory\n",
      "  warnings.warn(_MISSING_FILE_MESSAGE.format(filename))\n"
     ]
    }
   ],
   "source": [
    "import ProcessOT2DOE as process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load Sample Information\n",
    "* Will be in the form of a dataframe. This dataframe should be standardized in the original documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_info = pd.read_csv(r\"C:\\Users\\Edwin\\Desktop\\02_26_21_OuzoScan\\Sample_info\") # make it find the blank position from sample_info\n",
    "sample_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load UV-Vis Date\n",
    "* ***If loading from plate reader***: Once the plate has been read, allow for exporting to an excel sheet and reformat for easy upload and merging.\n",
    "    * The plate reader should automatically ask you if you would like to export to excel. When running multiple plates you can just keep selecting export and it will automatically add the new run as an additional sheet to the originally generated excel sheet. \n",
    "    * To format for easy loading:\n",
    "        1. Create a new sheet in the same exported excel file and name it something simple (i.e. sheet1). \n",
    "        2. Copy the data from the sheet and add it to the newly created sheet. **NOTE**: Make sure to paste in the data as \"only values\". \n",
    "        3. Repeat for every single exported sheet (i.e. every plate)\n",
    "* ***If loading from single cuvette reader***: \n",
    "\n",
    "* issue when over scanned on accident "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_wavelength_dfs(df_list):\n",
    "    merge_list = []\n",
    "    for i, df in enumerate(df_list):\n",
    "        if i == 0:\n",
    "            df = df\n",
    "        else: \n",
    "            df = df.drop(['Wavelength'])\n",
    "        print(len(df))\n",
    "        merge_list.append(df)\n",
    "    return pd.concat(merge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Edwin\\Desktop\\02_26_21_OuzoScan\\02_26_21_OuzoScan\\02_26_21_OuzoScan.xlsx\"\n",
    "plate_names = ['Sheet1','Sheet2','Sheet3','Sheet4','Sheet5']\n",
    "plate_dfs = process.extract_plates(path, plate_names) # can edit/remove wells accidently measured etc, but really should be done at excel level\n",
    "merged_df = merge_wavelength_dfs(plate_dfs) # a check\n",
    "merged_df[148:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Select/Locate Blank \n",
    "* ***If loading from plate reader***: Once the plate has been read, allow for exporting to an excel sheet and reformat for easy upload and merging.\n",
    "    * The plate reader should automatically ask you if you would like to export to excel. When running multiple plates you can just keep selecting export and it will automatically add the new run as an additional sheet to the originally generated excel sheet. \n",
    "    * To format for easy loading:\n",
    "        1. Create a new sheet in the same exported excel file and name it something simple (i.e. sheet1). \n",
    "        2. Copy the data from the sheet and add it to the newly created sheet. **NOTE**: Make sure to paste in the data as \"only values\". \n",
    "        3. Repeat for every single exported sheet (i.e. every plate)\n",
    "* ***If loading from single cuvette reader***: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# baseline and combine\n",
    "# baseline_series = merged_df.iloc[-1]\n",
    "# merged_baselined_df = baseline_correction(merged_df, baseline_series)\n",
    "combined_df = process.add_abs_to_sample_info(sample_info, merged_df)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df.to_csv(r\"C:\\Users\\Edwin\\Desktop\\OT2-DOE\\02_26_21_OuzoScan\\combined_data\", index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_open = pd.read_csv(r\"C:\\Users\\Edwin\\Desktop\\11_18_2020\\11_18_20_merged_info\")\n",
    "test_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data by dict method of df calling series\n",
    "wavelength = '400.0nm'\n",
    "x_name = combined_df['Component 4 wtf'][0]\n",
    "y_name = combined_df['Component 3 wtf'][0]\n",
    "x = [float(i) for i in combined_df['Component 4 wtf'][1:].tolist()][:-1] #ethanol, \n",
    "y = [float(i) for i in combined_df['Component 3 wtf'][1:].tolist()][:-1] # pfh\n",
    "z = [float(i) for i in combined_df[wavelength][1:].tolist()][:-1]\n",
    "combined_restricted_xyz = [x,y,z]\n",
    "modi = remove_visual_outliers(x,y,z,2) # this should only be used to find the new vmin and vmax but not to exclude"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
